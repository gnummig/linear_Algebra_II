\documentclass[11pt]{article}
\usepackage[english]{babel} % for theorem environent
\usepackage{amssymb}   % for number sets
\usepackage{amsmath}  % for \qed
\usepackage{german}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[shortlabels]{enumitem} % for enumeration 

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{beispiel}{Beispiel}
\newtheorem{satz}{Satz}
%\usepackage[Encodierer]{latin9}

\newcommand{\RN}[1]{%
  \textup{\uppercase\expandafter{\romannumeral#1}}%
}

\title{\textbf{Algebra $\RN{2}$}}
\author{Skript zur Vorlesung von Prof Fritzsche\\
		gesetzt von \\
		Daniel Mayer}
\date{}

\begin{document}

\maketitle

\section{Lineare Abbildungen}
Sei $\mathcal{K}$ ein  K"orper und V,W $\mathcal{K}$-Vektorräume
definition: Abbildung $\Phi : V \rightarrow W$ heißt 
\begin{enumerate}
 \item additiv, falls für $ \forall v_2, v_2 \in v$ gilt $\Phi(v_1+v_2)=\Phi(v_1)+\Phi(v_2)$
 \item homogen
 \item $\mathcal{K}$ linear falls $ \forall \alpha \in \mathcal{K} \forall v \in V \Phi (\alpha v)= \alpha\Phi (v)$ oder 
 \item epimorphismus falls $\Phi$ linear und surjektiv
 \item homomorphismus falls $\Phi $linear und injektiv
 \item isomorphismus falls whatever
\end{enumerate}

Die  vektorr"aume $V$ und $W$ heissen isomorph, falls ein isomorphismus $\Phi : V \rightarrow W$ existiert.\\
Im fall $V=W $wird ein $\mathcal{K}$homomorphismus auch auch endomorphismus genannt genauso wie ein isomorphismus auch antomorphismus.\\
Beispiel: Sei $\mu \in \mathcal{K}$, und $\Phi  : V \rightarrow V$ dann ist $\Phi (v) = \mu v$ eine lineare Abbildung dann 
$\forall v_1, v_2 \in V \forall \alpha \in \mathcal{K}$    
\[
  \Phi(v_1+v_2)= μ (v_1+v_2)= μ v_1 + μ v_2= \Phi(v_1)+\Phi(v_2)
\]
\[
  \Phi(\alpha v_1)=μ (\alpha v_1)= (μ\alpha)v_1=(\alpha μ)v_1= \alpha(μv_1)= \alpha\Phi(v_1)
\]
beispiel mit nullvektor fehlt

beispiel: sei $A \in \mathcal{K}^{Q\times P}$ dann ist $\Phi: \mathcal{K}^Q \rightarrow \mathcal{K}^P , \Phi (x)= A x$ linear denn $\forall x_1, x_2 \in \mathcal{K}$
\[
\Phi (x_1+x_2)= A(x_1+x_2)= A x_1+Ax_2= \Phi (x_1)+\Phi (x_2)
\]
\[
\Phi (\alpha x_1)=A(\alpha x_1)=\alpha Ax_1= \alpha \Phi (x_1)
\]bemerkung sei $ \Phi : V \rightarrow W $ dann ist $\Phi$ genau dann linear wenn $\forall v_1, v_2 \in V \forall \alpha_1 \alpha_2  \in \mathcal{K} : \Phi (\alpha x_1+\alpha x_2)=:\Phi (\alpha x_1)+\Phi (\alpha x_2)$
falls $\Phi$ linear so gilt $\Phi (\sum \alpha_iV_i )= \sum \Phi \alpha_iV_i \forall n \in \mathcal{N} v_1,...,v_n \in V alle \alpha_1,...,\alpha n \in \mathcal{K}$
warum gilt das nicht für$ n--> \inf$
\begin{beispiel}
 $V = C [a,b] \mathbb{R}$-vektorraum aller stetigen funktionen  $F:[a,b]  \rightarrow \mathbb{R} \Rightarrow \Phi : C [a,b]  \rightarrow \mathbb{R}$ gemäß $\Phi(f):= \int_{a}^{b}{f(x)dx}$ eine lineare Abbildung
\end{beispiel}
\begin{beispiel}
 sei V der $\mathbb{R}$-Vektorraum aller auf $\mathbb{R}$ definierten beliebig oft differenzierbaren reelwertigen funktionen,
 dann ist $\Phi (f)=f´$ eie lineare Abbildung $V \rightarrow W  $linear    ist, so 
 $:\forall v_1, v_2 \in V  \Phi (v_1-v_2)=\Phi (v_1)+(-1)v_2)= \Phi (v_1)+(-1)\Phi (v_2)=\Phi (v_1)-\Phi (v_2) \Rightarrow \Phi (-v_2)=-\Phi (v_2)$
\end{beispiel}

\begin{satz}
 Satz 9.1, sei $\Phi V \rightarrow W$ linnear und sei U ein unterraum von V, dann ist 
 $\Phi(U):= { w \in W | \exists v \in U w = \Phi (u)} $
 ein unterraum von W
Beweis: ommitted
sei $\alpha \in \mathcal{K}$dann $\alpha w_1  = \alpha\Phi(w_1)= \Phi(\alpha w_1) \in \Phi (U)= \Rightarrow (wegen S9.1) \Phi (U) $ ist Unterraum von W QED
\end{satz}


F9.2 sei$ \Phi V \rightarrow W$ eine  linneare Abbildung, dann ist das bild $\Im \Phi$ ein unterraum von W
beweis wende s9.1 für U=V an 
$\dim (\Im \Phi) \leq /dim W$
man nennt die dimension des Bildes $\Im \Phi $den Rang von$ \Phi $

\begin{satz}
 satz 9.3
sei $\Phi V \rightarrow W $eine  linneare Abbildung, des weiteren sei $\tilde{U}$ ein unterrraum von W dann ist das vollständige Urbild \[\Phi⁻(\tilde{U} ) = {v \in V: \Phi (v) \in \tilde{U} }\]
von $\tilde{U} $ unter $\Phi$ ein unterraum von V
\end{satz}

\begin{beispiel}
  beispiel $0_n \in \tilde{U} \Rightarrow \Phi(0_v)= O_w \in \tilde{U} \Rightarrow 0_v \in \Phi(\tilde{U} ) \Rightarrow \Phi(\tilde{U} ) \neq \emptyset$
sei $v_1, v_2 \in \Phi⁻(\tilde{U} ) \Rightarrow \Phi (v_1),\Phi(v_2) \in\tilde{U}  \Rightarrow \Phi (v_1+v_2)= \Phi (v_1)+\Phi(v_2) \in \tilde{U} ) \Rightarrow v_1+v_2 \in \Phi⁻(\tilde{U} ) $
sei $\alpha \in\mathcal{K}\Rightarrow \Phi(\alpha v_1)= \alpha \Phi(v_1) \in \tilde{U} \Rightarrow \alpha v_1 \in \Phi (tilde{U})\Rightarrow \Phi (\tilde{U} )$ ist unterraum von$ V  qed$

\end{beispiel}
F9.4
sei $\Phi V \rightarrow W $eine  linneare Abbildung, dann ist der Kern von $\Phi$ dh. die Menge$ \ker \Phi := {v \in V:\Phi (v) = 0_w}$ ein unterraum von V
beweis wende S9.3 für $\tilde{U}=0_w $an
bemerkung sei $\Phi V \rightarrow W $ linnear falls$ v_1, v_2  \in V$  derart dass 
$\Phi v_1 = \Phi v_2, so \Phi(v_1-v_2)=\Phi(v_1)-\Phi(v_2)= 0w, $ dh.
$ v_1-v_2\in \ker \Phi$
beweis: falls$ \ker \Phi ={0v}$ so folgt aus vorrausgehendem beweis die injektivität von $\Phi$
falls umgekehrt  $\Phi$ als injektiv vorrausgesetzt wird folg aus $\Phi 0_v = 0_w$ unmittelbar$ \ker\Phi={0_v}$.
\begin{beispiel}
 Sei A $\in \mathcal{K}P\times Q$ . für $\Phi: \mathcal{K}^q \rightarrow \mathcal{K}^P $gemäß $\Phi (x):= Ax$ gelten, dann 
$\Im \Phi = {\Phi (x): x \in \mathcal{K}^q}= {Ax:x\in \mathcal{K} ^q}=\mathcal{A}$
und $\ker \Phi = {x \in \mathcal{K} ^q: \Phi (x)0_px_1}={x \in \mathcal{K}^q: Ax= 0_px_1}=\mathcal{A}$
\end{beispiel}


\section{}
Bemerkung: sei U, V und W \K vektorraäume sowie \Psi : U-->V , \Phi : U-->V lineare abbilcung, dann ist auch \Phi\dot\Psi: U--> V eine lineare abbildung, denn 
\forall u1, u2 \in U, \alpha1 , alpha2 in \K 
\Phi\dot\Psi(\alpha_1 u_1 \alpha2 u_2)=\Phi(\Psi(\alpha_1 u_1 \alpha2 u_2))=\Phi(\Psi(\alpha_1 u_1)\Psi( \alpha2 u_2))= \alpha_1 \phi(\Psi(u1)) #missing
S 9.6 seien V und W \K vektorräume, wobei 1\leq q< \inf für q= \dim V erfülltsei des weiteren sieen v1, v2, ..., vn eine basisn von v wobei w1, w2, ...,wn \elememt W
dann gibt es genau eine lieare abbildung \Phi :v--> W mit \phi (v_i)=w_i für jjedes i in \Z
diese lineare abbildung \phi erfüllt \im \Phi = \span(w_1,w_2,...,w_n).
beweis: sei x \elem V , ==> \exist ! folge (\alpha_j)_{j=1}^k aus k mit x= \sum _{j=1}^k {\alpha_jv_j}==> (satz9.1)\phi(x) =
\phi \sum _{j=1}^q {\alpha_jv_j}= \sum _{j=1}^q {\phi(\alpha_jv_j)}==> wenn (1)
\Phi (x)}\sum _{j=1}^q {\phi(\alpha_jw_j)} ==> falls \phi eine lineare abbilcungmit (1) so eindeutig bestimmt
existens: Def \phi :V-->W derart dass jedem x \in \V wie oben mit seiner Basisdarstellung zugeordnet wird: 
\Phi(x):= \sum _{j=1}^q {\phi(\alpha_jw_j)}
Nachweis von (1): \foarll k in \Z_{1,q}: v_k=\sum _{j=1}^q \delta_{jk}v_i     (3)
==> \forall k \in \\Z_{1,q}\phi(v_k)=\sum _{j=1}^q\delta_{jk}w_i= w_k ==> (1) erfüllt
nnachweis der linearität von \Phi:
seien x,y \elem  V sowie \alpha,\beta \elem \k : ==> \exist ! (\alpha_i)_{j=1}^q aus \K mit (2) ind y= \sum _{j=1}^k {\beta_jw_j} (5)
==> \alpha x +\beta y= \alpha \sum _{j=1}^k {\alpha_jv_j} + \sum _{j=1}^k {\beta_jw_j}= \sum _{j=1}^k {\alpha \alpha_j+\beta \beat_j}= \Phi(\aölpha x+ \beta y)
= \sum _{j=1}^k {\alpha \alpha_j+\beta \beat_j}w_i= 
\alpha \sum _{j=1}^k {\alpha_jv_j+\beta \sum _{j=1}^k {\beta_jw_j}= \alpha \Phi(x)+\beta \Phi (y)00> \phi linear

\foral x \in V \Phi(x):= \sum _{j=1}^q {\phi(\alpha_jw_j)} \elem \span'(w1,...,wq)==> im \pohi \leq \span'(w1,...,wq)  (6)
sei umgekehrt w \elem  \span'(w1,...,wq) vorgegeben ==> \exist \gamma_1,...,\gamma_q \in \K: w=\sum _{j=1}^k {\gamma_jw_j}
==> w= \sum _{j=1}^q {\beta_j\Phi(v_i)}= \phi (\sum _{j=1}^k {\beta_jv_j) \elem Im\Phi 
==> \span'(w1,...,wq} \subseteqq \Im \Phi 
F9.7 seien V und W \k Vr wobei 1\leqdimV<+\inf, sei r\elem \N sowie v_1,v_2,..,v_r \elem V und w_1,w_2,..,w_r \elem W
sei vorrausgesetz dass v_1,..,v_r linear unabhängig, dann gibt es mindestens eine lineare abbildung \Phi :V--> W, mit \Phi(v_j)=W_j \forall j\elemN_{1,r}
beweis:  Nach Basisergänzungssatz r\leq q im Fall r=q wende s 9.6 an . im fall r<q können nach Basisergänzungssatz vektoren v_r+1,...,v_q\elem V 
derart ergänzt werden, dass v_1,...,v_r,v_r+1,...,v_q eine basis von V ist ind wir können S 9.6 anwenden \QED
\Bemerkungaus dem beweis von folgerung 9.7 ist ersichtlich, dass im fall dass r<q und W\neq {0_w} die lineare abbildung nicht eindeutig bestimmt ist.
L9.8
seien Vun d W \K vr sowie \Phi :v--> W  eine lineare abbildung, dann gilt \dim \Im \Phi\leq dim V.
%übung Unterscheidung dimV= \inf, dim V\elem \n, dim V =0
S9.9 seien V und W \K-Vektorräume  wobei dim V < \inf, sowie \Phi :v--> W  eine lineare abbildung dann gilt \dim (\Im \Phi\)+dann gilt \dim (\ker\Phi\)= dim V
%beweis in Übung
Definition:seien V und W \K-Vektorräume  sowie \Phi :v--> W eine lineare abbildung dann heißt Rang_K von \Phi .= \dim (\Im \Phi\) der Rang von \Phi 
Satz 9.10 seien V und W \K-Vektorräume sowie \Phi :v--> W  eine lineare abbildung
(a) falls \phi injektiv, so ist die Umkehrbildung \Phi^{-1} : \Im \Phi --> V ebenfalls linear
(b) im fall dass dim V = dim W <\inf gilt, sind folgenda aaussagen äquivalent:
  1 \phi ist bijektiv
  11 \Phi ist injektiv
  111  \phi ist surjektiv

wiederholung: koordinaten abbildung siehe Algebra 1
Bemerkung: betravchten wir die natürliche basis B:= (e^{(q)}_1,e^{(q)}_1,...,e^{(q)}_q) ) des \K^q gilt für jede wahl von x=(x_1,x_2,...,x_q)^T  
\elem \K^q 
die beziehung \Omega(x) =x wegen x= \sum_{j=1}^q x_j e_j^{(q)}
das folgende theorem ist grob gesagt die grndlage dafür, dass das rechnen in (nicht trivialen) endlich dimensionalen \K Vektorräumen auf das renchen in 
\K^q zurückgeführt weden kann, wobei q die dimension des urbildvektorraumes der linearen abbildung darstellt.


S9.11
sein q \elem \N sowie V ein \k Vr mit dim V = q bezeichne (v_1,...,v_q) eine basis von V dann sit die koordinatenabbildung \Omega_B: V--> \K^q bezüglich der geordneten
basis B ein isomorphismus insbesondere sind V und K^q
isomorphismusdie gemäß S9.6 durch die bedingung \Phi_B (e_j^{(q)})=vj \forall j in \Z_q eeoindeutig bestimmte lineare abbildung\OPh _B: K^q--> V
% \Phi_B = \Omega_B^{-1}

\section{beweis 9.11}
wir zeigen zundächst, dass $\Omega_B: V \rightarrow \K^q bijektiv ist $
\begin{item}
 \item $\Omega_B $ist surjektiv, denn : ist 
 $
 \begin{pmatrix}
  \alpha_1\\ \vdots\\ \alpha_q
 \end{pmatrix}
\in K^q
 $
 beliebig, so erfüllt $\mathbb{x}:= \sum_{j=1}^{q}\alpha_j \mathbb{v}_j$ dann ist 
\[ \omega_b(\mathbb{x}=
 \begin{pmatrix}
  \alpha_1\\ \vdots\\ \alpha_q
 \end{pmatrix})\]
 \item Omega_B ist injektiv, denn Seien $\mathbb{x,y}\in V$ beliebig, mit $\Omega_B(\mathbb{x})=\Omega_B(\mathbb{y})$
 mit $\alpha_j := (e_j^(q))^T\Omega_B(\mathbb{x}), j=1,2,..., q$, gilst also  
 \[\begin{pmatrix}
  \alpha_1\\ \vdots\\ \alpha_q
 \end{pmatrix}\]
\[ =\Omega_B(\mathbb{x})=\Omega_B(\mathbb{y}
\]
\[==> \mathbb{x}=\sum_{j=1}^{q}\alpha_j \mathbb{v}_j= \mathbb{y}
\] ==> Omega_B ist bijektiv
 \item
 $\Omega_B $ ist klinear denn seien $\mathbb{x,y}\in V in \lambda, \mu \in \k$ Mit $\alpha_j := (e_j^(q))^T\Omega_B(\mathbb{x})$ und $\beta_j:= (e_j^(q))^T\Omega_B(\mathbb{y}),j=1,2,..., q$
  
  gilt, dann 
  \[\Omega_B(\mathbb{x}=
  \begin{pmatrix}
  \alpha_1\\ \vdots\\ \alpha_q
 \end{pmatrix}
 \quad
 \Omega_B(\mathbb{y}=
  \begin{pmatrix}
  \beta_1\\ \vdots\\ \beta_q
 \end{pmatrix}\]
 sowie \[\mathbb{x}=\sum_{j=1}^{q}\alpha_j \mathbb{v}_j und \mathbb{y}=\sum_{j=1}^{q}\beta_j \mathbb{v}_j=\] 
 \[==> \lambdax +\my y= \mathbb{x}=\alpha \sum_{j=1}^{q}\alpha_j \mathbb{v}_j + \mathbb{y}\my\sum_{j=1}^{q}\beta_j \mathbb{v}_j
 = \sum_{j=1}^{q}(\lambda\alpha_j+\my\beta_j )\mathbb{v}_j= \omega_B \lambdax+\muy\]
 \[=
 \begin{pmatrix}
  \lambda\alpha_1+\mu \beta_1\\ \vdots\\ \lambda\alpha_q\mu\beta_q
 \end{pmatrix}
 =\lambda\begin{pmatrix}
  \alpha_1\\ \vdots\\ \alpha_q
 \end{pmatrix}
 +\mu\begin{pmatrix}
  \beta_1\\ \vdots\\ \beta_q
 \end{pmatrix}
 \]
\end{item}
nach satz 9.6 gibt es genau dann eine lineare abbildung wenn $\Phi _B : \K^q--> V$ , it 
\phi_B(e_j^(q))

#ommitted

\section{lemma 9.12}
seien $q \in \mathbb{N}$ und $V,W \mathcal{K}$-Vektorräume, wobei $\dim v=q$ gelten weiter sei $v_1,...,v_q$ eine basis vom $V $und $\Phi: V--> W$ eine lineare Abbildung, dann gelten:
\begin{enumerate}[a)]
 \item Im $\Phi = span (\Phi(v_¹),...,\phi(v_2))$ insbesondere ist $\Phi$ genau dann surjektiv wenn $\Phi(v_1) ,..., \Phi(v_q)$ ein ein erzeugendensystem von $W$ ist.
 \item $\Phi$ ist ganau dann injektiv, wenn $\Phi(v_1),..., \Phi(v_q)$ lin unabhängig sind
 \item $\Phi$ ist ganau dann bijektiv, wenn $\Phi(v_1),..., \Phi(v_q)$ eine basisi von $W$ ist
\end{enumerate}

\section{beweis(im seminar)}
\section{satz9.13}
seien $V,W \mathcal{K}-Vektorräume$ mit $\dim V < \inf$ dann sind $V$ und $W$ genau dann isomorph wenn $\dim V=\Dim W $gilt.
\subsection{beweis im seminar, 5pkt}
\subsection{lemma 9.14}
seine $p,q \in \mathbb{N}$ sowie $\phi : \k^q-->\K^p$ eine lineare abbildung, dann gibt es genau dann eine Matrix $\mathbb{A} \in \K^{p\times q}$ mit $\Phi(x)=Ax$
für alle $x \in \k^q$, nämlich $A= (\Phi(e_1^(q)),...,\Phi(e_q^(q)))$
\subsection{beweis}
Sei $B:= (\Phi(e_1^(q)),...,\Phi(e_q^(q)))$. nach Bsp ist $\Psi:\K^q-->\K^p$ gemäß $\Psi(x):= Bx$
eine lin. abb. für alle $j=1,2,...,q$ gilt $\Phi (e_j^(q))= B(e_j^(q))= \Psi(e_j^(q))$
==>(s9.6) $\Phi=\Psi$
==> $A=B$ ist eine matrix aus $\K^{p\times q}$ mit 
1
für alle $x \in \K^q$
sei nun $A \in \K^{p \times q}$  beliebig mit (1)für alle $x in \K^q$
\[==> A=A*I_q=A(e_1^(q)),...,(e_q^(q))=(Ae_1^(q)),...,A(e_q^(q))\]
=(1)
\[(\Phi e_1^(q)),...,\phi(e_q^(q))\]
qed
Im fall von lemma 9.14 ist die Unterscheidungvon ,lin abb $ \phi : \k^q-->\K^p $und matritzen aus \K^p\times q also nicht wesentlich . eine solchen 
zusammenhang zwischen linearen abbildungen und matrizen gibt es jedoch nuc in den Standardräumen .

\section{Satz9.15}
seinen $  p,q \in \mathbb{N}$ sowie $V$ und $W$ $\mathcal{K}$ VR mit $\dim V =q $und $\dim W =p $ weiter sie $B= (v_1,...,v_q)$
eine  (geordnete) basis von $V$ ist und $C=(w_1,...,w_p)$ eine (geordnete) basis von $W$ ist 
sowie $\Phi: V--> W$ eine lineare abbildung
a)
es gibt eine matrix $A= (\alpha_{jk})_{j=1,...,q\\ k=1,...,p} \in \K^{p\times q}$ mit 
$\phi (v_k)= \sum_j=1^p{\alpha_{jk}w_j}$ für alle $k=1,...,q$, 
nämlich $A = (\omega_C(\Phi(v_1),...,\omega_C(\Phi(v_q))$ wobei  $\Omega_C : W--> \k^p$ die koordinatenabbildung bezüglich der basis $C$ in $W$ ist
b)
Es gibt genau eine matrix $\tilde{A} \in \K^{p\times q}$ mit 
$\Omega_C(\Phi(v))=\tilde{A}_\Omega_B (v)$ für alle $v in V$ (3)
nämlich \tilde{ A}=A
beweis:
a)
für jedes $k=1,...,q$ besitzt der Vektor $\Phi (v_k) $aus $W$ gemäß lemma 3.6 eine eindeutige Darstellung $\Phi (v_k)= \lambda^{(k)}_1w_1,...,\lambda^{(k)}_p w_p$
bezüglich der Basis $C$ in $W$ Mit $\lambda_{jk}:= \lambda^{(k)}_j, j=1,...,q$ folgt (1)
==> $A \in \K^{p\times q}$ mit (1) existiert und ist eindeutig bestimmt.
Für alle $k=1,...,q $folgt ais (1) 
\[\begin{pmatrix}
 \alpha_{1k}\\ \alpha_{2k}\\ \vdots \\ \alpha_{pk}
\end{pmatrix}
=
\begin{pmatrix}
 \lambda^{(k)}_1\\ \vdots\\ \lambda {(k)}_p
\end{pmatrix}
=\Phi(v_k)\] also (2)
b) sei v in V beliebig Mit $\beta_k:= (e^q_k)^T \Omega_B(v) k=1,...,q $ist 
\[\begin{pmatrix}
 \beta_1\\ \vdots \\ \beta_q
\end{pmatrix}
\]
\[= \omega_B(v) dann haben wir v= \sum_j=1^p{\beta_{k}v_k} und wegen der linearität von \Phi und (1) somit 
\Phi(v)=\sum_j=1^p{\beta_{k}\Phi(v_k)}
= (1)
\sum_j=1^p{\beta_{k}\sum_j=1^p{\alpha_{jk}(w_j)}}
=
\sum_j=1^p{\beta_{k}(\sum_j=1^p{\alpha_{jk}\beta_k)w_j}}
\]
==> 
\[\Omega_C(\phi(v))=
\begin{pmatrix}
 \sum_j=1^p{\alpha_{1k}\beta_k\\
 \vdots\\
  \sum_j=1^p{\alpha_{1k}\beta_k\\
\end{pmatrix}
=\begin{pmatrix}
  \alpha_{11}& \hdots & \alpha_{1q}\\
  \hdots&\ddots&h\hdots\\
  \alpha_{p1}&\hdots& \alpha_{pq}
\end{pmatrix}
\begin{pmatrix}
 \beta_1\\
 \vdots\\
 \beta_q\\
\end{pmatrix}
= A\Omega_B(v).
\]==> $\tilde{A}:= A$ erfüllt (3) sei nun $\tilde{ A} \in \K^{p\times q}$ beliebig mit (3) 
für alle $k=1,...,q$ ist wegen $v_k= \sum \delta_{jk}v_k= 0v_1+...+1v_k+...+0v_q$
zunächst \[\omega_B (v_k)= 
\begin{pmatrix}
 0\\
 \vdots\\
 1_k\\
 \vdots\\
 0\\
\end{pmatrix}
= e_k^(q)\] und wegen (3) folglich 
\[\Omega_C(\phi(v_K))= \tilde{A} \Omega_B(v_k)=\tilde{A}e_k^(q)= kte spalte vom \tilde{A} \](4)
==>
\[\tilde{A}=\tilde{A}I_q =\tilde{A}(e_1^(q)),...,(e_q^(q))=(\tilde{A}e_1^(q)),...,\tilde{A}(e_q^(q))= (\Phi e_1^(q)),...,\phi(e_q^(q))=A
\]
\section{bemerkung}
es liegen die situation von satz 9.15 vor 
dann heißt die durch (2) gegebene Matrix $A \in  \K^{p\times q} $die darstellungsmatrix der lin abb $\Phi :V-->W$ bzw der geordneten basen $B$ und $C$
für $A$ wird dann $\Phi _{B,C}$ geschrieben
Kennt man die matrix $\Phi _{B,C}$ so lässt sich gemäß (3) dann $\Phi (v) $für jedes $v \in B $ wie folgt berechnen:
ist $v=\sum \beta_kv_k$ die darstellung vom $v$ bzw $B$ so bildet man 
$(\beta_1,..., \beta_q) $ und erhält $\Phi(v)$ gemäß $\sum \gamma_jw_j$.
% 12.04.2017
$\Phi : V \rightarrow W, B:= (v_1,...,v_q) , C=(w_1,...,w_p)$
$\Omega_C[\Phi(v)]=\mathbb{\Phi}_{B,C}\Omega_B(v) \quad \forall v \\in V$
betrachten $M_\mathbb{\Phi}_{B,C}: \mathcal{K}^q \rightarrow \mathcal{K}^p$ gemäß $M_\mathbb{\Phi}_{B,C}(x)=\mathbb{\Phi}_{B,C}(x)$
Diagramm:
q:= dim V  
p:= dim W
\begin{matrix}
 V & \rightarrow^\Phi & W\\
 \Omega_B \downarrow & & \uparrow \Omega_C\\
 \mathcal{K}^q & \rightarrow^{M_\mathbb{\Phi}_{B,C}} & \mathcal{q}\\
\end{matrix}

B.: Im spezialfall V = K^q und W= K^p sowie B:= (e^{(q)}_1,e^{(q)}_1,...,e^{(q)}_q) und C:= (e^{(p)}_1,e^{(p)}_1,...,e^{(p)}_p) 
ist \mathbb{\Phi}_{B,C} gerade die in 9.14 beschriebene Matrix A welche $\Phi(x)=A(x)$ $\forall x \in \mathcal{K}^q$ erfüllt (vgl bemerkung vor theorem 9.10)
\begin{lemma}
 seine $p,q n \in \mathbb{N}$ sowie V und W K VR mit $ \dim V=q $ und $\dim W= p$ des weiteren sei B:=(v_1,...,v_q) eine basisi von V und C:= (w_1,,..,w_p) eine basis von W Für jedes $A\in \mathbb{C}$ gibt es genau dann eine lineare abbildung $\Phi:v \rightarrow W$ mit $\mathbb{\Phi}_{B,C}=A$
 
\end{lemma}
\begin{beweis}
 sei $\Phi: V \rightarrow W$ gemäß $\Phi(v):= \sum_{j=1}^p (e^{(p)}_j)^T A \Omega_B(v) w_j $ (1) definiert ==> 
 $\forall v,v' \in V: \Phi(v +v')=^(1) \sum_{j=1}^p (e^{(p)}_j)^T A \Omega_B(v+v') w_j = ...= \Phi(v)+ \Phi(v');$
 $\forall \alpha \in K : \Phi (\alpha v) =^(1)  \sum_{j=1}^p (e^{(p)}_j)^T A \Omega_B(\alpha v+) w_j=\alpha \Phi (v)$
 ==> $\Phi $ linear
 $\forall v \in V \Omega_C[\Phi(v)]=^(1) 
 \begin{pmatrix}
 (e^{(q)}_1)^T A \Omega_B(v)\\
 \vdots\\
 e^{(q)}_1)^T A \Omega_B(v)
 \end{pmatrix}
 =
  \begin{pmatrix}
 (e^{(q)}_1)^T \\
 \vdots \\
 e^{(q)}_1)^T A 
 \end{pmatrix}
 A \Omega_B(v)
 = I_p A \Omega_B(v) ==> ^{thm 9.15} \mathbb{\Phi}_{B,C}$
 ==> existent
 eindeutigkeitsnachweis:
 sei $\Psi: V\rightarrow W$ eine beliebige lineare abbildung mit $\mathbb{\Psi}_{B,C}=A$
 $ \forall k in \Z_{1...q}: \Omega_C[\Phi(v_k)]= \mathbb{\Psi}_{B,C}\omega_B(v)= A e_k^{(q)}
=\mathbb{\Phi}_{B,C}e_k^{(q)}=\mathbb{\Phi}_{B,C}\Omega_B(v_k)=^(S9.15) \Omega_C(\Phi(v_k))
$
==> \forall k in \Z_{1...q} \Psi(v_k)=\Phi(v_k)
==>^(9.6) \Phi=\Psi
QeD
\end{beweis}
\begin{Satz9.17}
 siein V und W k VR dann ist die menke HOM_K (V,W) aller K homomorphisen von V unc W ein interraum des K VR abb(v,W) aller abbildungen von V nach W
 beweis : übung
 V* := HOM_K(V,W) neannt werden nt man bektorraum vn v dessen elemente linearformen von V gen
\end{Satz}
\begin{satz 9.18}
 seien $p,q in \mathbb{N} sowie V und W K VR $ mit $dim V=Q$ und dim W=p daes weiteren seienB:=(v_1,...,v_q) eine basisi von V und C:= (w_1,,..,w_p) eine basis von W dann ist \mathcal{M}_{B,C}: Hom_K(V,W) \rightarrow \k^pxq gemäß \Phi \rightarrow \mathbb{\Phi}_{B,C} ein isomorphismusv von K VRäumen
 beweis übung
\end{satz 9.18}
\begin{satz}
 seien $r,p,q in \mathbb{N} $ sowie U,V,W KVR mit dimu=r, dim V=q, dimW=p des weiteren seien B_V:=(v_1,...,v_q) eine basisi von V und B_W:= (w_1,,..,w_p) eine basis von W weiterhin seine  \Psi :U-->V \Phi: V--> W lineare abbildung dann ist  \Chi:=\Phi ° \Psi eine lineare abb mit darstellungsmatrix \mathbb{\Chi}_{B_U,B_W} die gleichung \mathbb{\Chi}_{B_U,B_W} = \mathbb{\Phi}_{B_U,B_W}\dotfill \mathbb{\Psi}_{B_W,B_V}
 
\end{satz}
\begin{beweis}
 nach bem vor 9.6 ist \chi neine lineare abb nach 9.15 \Omega_B_W[\Phi(v)] = \mathbb{\Phi}_{B_U,B_W} \Omega_B_v(v) \forall v \in V (1)
 \forall l \in \mathbb{Z}_{1,..,r}: \Psi(v_l) \in V
 ==> 
 \omega_B_W[\Chi(u_l)]= \Omega_B_W[\Phi(\psi(v_l))]= \mathbb{\Phi}_{B_V,B_W}\mathbb{\Psi}_{B_U,B_V} e^{(r)}_l \forall l \in \mathbb{Z}_{1,l}
 (3) \Chi_{B_U,B_W}=\Chi_{B_U,B_W} I_r= \Chi_{B_U,B_W} (e^{(r)}_1,...,e^{(r)}_r)= (\Chi_{B_U,B_W}e^{(r)}_1,...,\Chi_{B_U,B_W}e^{(r)}_r)
 (\mathbb{\Phi}_{B_V,B_W}\mathbb{\Psi}_{B_U,B_V} e^{(r)}_1,..,\mathbb{\Phi}_{B_V,B_W}\mathbb{\Psi}_{B_U,B_V} e^{(r)}_r)
 =\mathbb{\Phi}_{B_V,B_W}\mathbb{\Psi}_{B_U,B_V}e^{(r)}_1,...,e^{(r)}_r)=\mathbb{\Phi}_{B_V,B_W}\mathbb{\Psi}_{B_U,B_V}
 QED
 
 
\end{beweis}
\begin{matrix}
 U &  & rightarrow^{\Phi=\Psi}& & W\\
 &\searrow_\psi & &\nearrow_\psi&\\
 &&V & &\\
 \Omega_B_V\downarrow & & \downarrow\omega_B_V & & uparrow \omega^{-1}_B_W\\
 && K^q&&\\
 & &\nearrow&& \searrow
 \K^r rightarrow\k^p
 
\end{matrix}
\begin{lemma}
 seine q in N sowie v ein KVR mit dim V=q des weiteren seien B:=(v_1,...,v_q) und B':=(v'_1,...,v'_q) basen von V 
 weiterhin sei \Phi  eine lineare abbildung . dann ist \phi genau dann bijektiv, wenn \mathbb{\Phi}_ {B,B'} invertierbar ist. in diesem fall ist 
 (\mathbb{\Phi}_ {B,B'})^{-1} gerade die darstellungsmatrix der (gemäß s 9.10) abbildung \Phi{-1} bezüglich der basis B und B'
\end{lemma}
beweis : übungsaufgabe
\begin{lemma}
%9.21
seine q \in \N udnV einKVR mit $\dim V=q$ Des Weiteren seien B':=(v'_1,...,v'_q) eine basisi von V sowie $v_1,...,v_q \in V$
bezeichne \Gamma:=(\gammma_{jk})_{j,k=1,..,q} die eindeutig bestimmte kompexe qxq matrix, für die $v_k=\sum_{j=1}^q\gamma_{jk} v'j$ für jedes k \in \mathbb{Z}_{1,q} gilt dann ist  B:=(v_1,...,v_q) eine basis von V wenn $\Gamma$ invertierbar ist.
\end{lemma}







\end{document}
